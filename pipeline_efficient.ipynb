{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import mlflow\n",
    "from time import time\n",
    "import hiddenlayer as HL\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# i made all of these !\n",
    "from models import Backbone as Model\n",
    "from video_loader import vidSet\n",
    "from utils import Params, count_parameters\n",
    "from loss import ConstrastiveLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want a class for our parameters because it is wayyyy easier to log them this way \n",
    "args = Params(10, 1, 0.00005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 26 10:38:42 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN V             Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 28%   30C    P8    23W / 250W |   1271MiB / 12066MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:83:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P0    33W / 250W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  TITAN V             Off  | 00000000:84:00.0 Off |                  N/A |\r\n",
      "| 21%   36C    P0    34W / 250W |      0MiB / 12066MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      4050      C   ...a/conda/envs/goofit-june2020/bin/python  1259MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "# for running in command line \n",
    "# watch -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_path = '/share/lazy/will/ConstrastiveLoss/bdd100k/videos/New'\n",
    "\n",
    "path_list = []\n",
    "for (dirpath, _, filenames) in os.walk(videos_path):\n",
    "    for filename in filenames:\n",
    "        path_list.append(os.path.abspath(os.path.join(videos_path, filename)))\n",
    "\n",
    "# takes a list of file paths to .mp4s and returns a dataloader ov the frames\n",
    "vidset_train = vidSet(path_list[:100])\n",
    "\n",
    "vidloader_train = DataLoader(vidset_train, batch_size=args.batch_size, shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(4):\n",
    "    plt.imshow(next(iter(vidloader_train))[i].permute(1,2,0).int())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the file path where the logs will be stored. this should be a global reference since many different scripts will reference it from different directories\n",
    "mlflow.tracking.set_tracking_uri('file:/share/lazy/will/ConstrastiveLoss/Logs')\n",
    "\n",
    "# a new experiment will be created if one by that name does not already exists\n",
    "mlflow.set_experiment('Constrastive loss unsupervised')\n",
    "\n",
    "\n",
    "def train(model, train_data, loss, optimizer):\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        t0 = time()\n",
    "        train_loss = 0\n",
    "\n",
    "        for batch_idx, img_tensor in enumerate(train_data):\n",
    "\n",
    "            # select FOUR images total, two pos two neg. the forward pass size is 1 gb for the overparameterized model so it is important\n",
    "            # to pick a combination that fits into memory. \n",
    "\n",
    "            # Select 2 positives, or the first 2 frames\n",
    "            positives_tensor = img_tensor[:2].to(device)\n",
    "\n",
    "            # this I THINK selects the last two images in a sequence, loss does not count observations of the same class, so it is ok that they are similar\n",
    "            # however it may be slower to learn.\n",
    "            negatives_tensor = img_tensor[3:5].to(device)\n",
    "\n",
    "            # set parameter gradients to zero \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: compute the output\n",
    "            positive_latent_tensor = model(positives_tensor)\n",
    "            negative_latent_tensor = model(negatives_tensor)\n",
    "\n",
    "            # Computation of the cost J\n",
    "            cost = loss(positive_latent_tensor, negative_latent_tensor)  \n",
    "\n",
    "            # Backward propagation\n",
    "            cost.backward()  # <= compute the gradients\n",
    "            train_loss += cost.item()\n",
    "\n",
    "            # Update parameters (weights and biais)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Basically like having a batch size of 2, hoping this helps with the data transfer bottleneck since \n",
    "            # i can have the data loader doing stuff in the background with pin_memory, more time/compute per batch\n",
    "            positives_tensor = img_tensor[6:8].to(device)        \n",
    "            negatives_tensor = img_tensor[9:11].to(device)\n",
    "            \n",
    "            # Forward pass: compute the output\n",
    "            positive_latent_tensor = model(positives_tensor)\n",
    "            negative_latent_tensor = model(negatives_tensor)\n",
    "\n",
    "            cost = loss(positive_latent_tensor, negative_latent_tensor)\n",
    "            cost.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += cost.item()\n",
    "        t1 = time()\n",
    "\n",
    "        \n",
    "        ret = {'Train Loss':train_loss, 'Epoch time':t1-t0}\n",
    "        yield ret.items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/06/26 10:39:06 WARNING mlflow.tracking.context.git_context: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: [Errno 11] Resource temporarily unavailable\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from models import Backbone as Model\n",
    "\n",
    "model = Model().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "loss = ConstrastiveLoss(device=device)\n",
    "\n",
    "run_name = 'Ten videos'\n",
    "with mlflow.start_run(run_name = run_name) as run:\n",
    "    for key, value in vars(args).items():\n",
    "        mlflow.log_param(key, value)\n",
    "\n",
    "    mlflow.log_param('Parameters', count_parameters(model))\n",
    "\n",
    "    for epoch, items in enumerate(train(model, vidloader_train, loss, optimizer)):\n",
    "        for key, value in items:\n",
    "            print(key, value)\n",
    "            mlflow.log_metric(key, value, epoch)\n",
    "\n",
    "    torch.save({\n",
    "        'model':model.state_dict(),\n",
    "        'optimizer':optimizer.state_dict(),\n",
    "        }, 'run_stats.pyt')\n",
    "    mlflow.log_artifact('run_stats.pyt')\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # save an architecture diagram\n",
    "    HL.transforms.Fold(\"Conv > BatchNorm > Relu\", \"ConvBnRelu\"),\n",
    "    HL.build_graph(model, torch.zeros([args.batch_size, 3, 288, 512]).to(device)).save('architecture', format='png')\n",
    "    mlflow.log_artifact('architecture.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

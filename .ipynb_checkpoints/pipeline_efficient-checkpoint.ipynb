{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow ui --port 6007 --backend-store-uri file:/share/lazy/will/ConstrastiveLoss/Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import mlflow\n",
    "from time import time\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# i made all of these !\n",
    "from models import Backbone as Model\n",
    "from video_loader import vidSet\n",
    "from utils import Params, count_parameters\n",
    "from loss import ConstrastiveLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want a class for our parameters because it is wayyyy easier to log them this way \n",
    "args = Params(4, 10, 0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 27 00:04:22 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  On   | 00000000:18:00.0 Off |                  N/A |\r\n",
      "| 39%   64C    P3   103W / 250W |      1MiB / 11019MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 208...  On   | 00000000:3B:00.0 Off |                  N/A |\r\n",
      "| 29%   32C    P8    21W / 250W |     61MiB / 11019MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1   N/A  N/A      3787      G   /usr/bin/X                         33MiB |\r\n",
      "|    1   N/A  N/A      3843      G   /usr/bin/gnome-shell               25MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "# for running in command line \n",
    "# watch -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_path = '/share/lazy/will/ConstrastiveLoss/bdd100k/videos/New'\n",
    "\n",
    "path_list = []\n",
    "for (dirpath, _, filenames) in os.walk(videos_path):\n",
    "    for filename in filenames:\n",
    "        path_list.append(os.path.abspath(os.path.join(videos_path, filename)))\n",
    "\n",
    "# takes a list of file paths to .mp4s and returns a dataloader ov the frames\n",
    "# vidset_train = vidSet(path_list[10:20])\n",
    "\n",
    "# vidloader_train = DataLoader(vidset_train, batch_size=args.batch_size, shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not use except to compare stuff\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# for i in range(4):\n",
    "#     plt.imshow(next(iter(vidloader_train))[i].permute(1,2,0).int())\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the file path where the logs will be stored. this should be a global reference since many different scripts will reference it from different directories\n",
    "mlflow.tracking.set_tracking_uri('file:/share/lazy/will/ConstrastiveLoss/Logs')\n",
    "\n",
    "# a new experiment will be created if one by that name does not already exists\n",
    "mlflow.set_experiment('Constrastive loss unsupervised')\n",
    "\n",
    "\n",
    "def train(model, loss, optimizer):\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        t0 = time()\n",
    "        train_loss = 0\n",
    "\n",
    "        vidset_train = vidSet(path_list[int(10*epoch):int(10*(epoch+1))])\n",
    "        vidloader_train = DataLoader(vidset_train, batch_size=args.batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "        for batch_idx, img_tensor in enumerate(vidloader_train):\n",
    "\n",
    "            # select FOUR images total, two pos two neg. the forward pass size is 1 gb for the overparameterized model so it is important\n",
    "            # to pick a combination that fits into memory. \n",
    "\n",
    "            # Select 2 positives, or the first 2 frames\n",
    "            positives_tensor = img_tensor[:2].to(device)\n",
    "\n",
    "            # this I THINK selects the last two images in a sequence, loss does not count observations of the same class, so it is ok that they are similar\n",
    "            # however it may be slower to learn.\n",
    "            negatives_tensor = img_tensor[-2:].to(device)\n",
    "            # set parameter gradients to zero \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: compute the output\n",
    "            positive_latent_tensor = model(positives_tensor)\n",
    "            negative_latent_tensor = model(negatives_tensor)\n",
    "\n",
    "            # Computation of the cost J\n",
    "            cost = loss(positive_latent_tensor, negative_latent_tensor)  \n",
    "\n",
    "            # Backward propagation\n",
    "            cost.backward()  # <= compute the gradients\n",
    "            train_loss += cost.item()\n",
    "\n",
    "            # Update parameters (weights and biais)\n",
    "            optimizer.step()\n",
    "\n",
    "        t1 = time()\n",
    "\n",
    "        \n",
    "        ret = {'Train Loss':train_loss, 'Epoch time':t1-t0}\n",
    "        yield ret.items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/miniconda3/envs/june2020-gpu/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss:  18.925437927246094\n",
      "Batch Loss:  0.7601163387298584\n",
      "Batch Loss:  0.5984195470809937\n",
      "Batch Loss:  0.16094940900802612\n",
      "Batch Loss:  0.17369064688682556\n",
      "Batch Loss:  0.4712296724319458\n",
      "Batch Loss:  0.17389678955078125\n",
      "Batch Loss:  0.2209552526473999\n",
      "Batch Loss:  0.23838788270950317\n",
      "Batch Loss:  0.07251717895269394\n",
      "Batch Loss:  0.11965159326791763\n",
      "Batch Loss:  0.06989303976297379\n",
      "Batch Loss:  0.12178795784711838\n",
      "Batch Loss:  0.3400575518608093\n",
      "Batch Loss:  0.06394194066524506\n",
      "Batch Loss:  0.03485114872455597\n",
      "Batch Loss:  0.06378179043531418\n",
      "Batch Loss:  0.03020494058728218\n",
      "Batch Loss:  0.025658018887043\n",
      "Batch Loss:  0.10041036456823349\n",
      "Batch Loss:  0.06624573469161987\n",
      "Batch Loss:  0.011337397620081902\n",
      "Batch Loss:  0.01702871359884739\n",
      "Batch Loss:  0.014983877539634705\n",
      "Batch Loss:  0.034088097512722015\n",
      "Batch Loss:  0.0726778507232666\n",
      "Batch Loss:  0.0484769344329834\n",
      "Batch Loss:  0.1296844780445099\n",
      "Batch Loss:  0.021735990419983864\n",
      "Batch Loss:  0.02243794873356819\n",
      "Batch Loss:  0.3588867485523224\n",
      "Batch Loss:  0.014495713636279106\n",
      "Batch Loss:  0.023116981610655785\n",
      "Batch Loss:  0.014816218987107277\n",
      "Batch Loss:  0.02671804465353489\n",
      "Batch Loss:  0.016349544748663902\n",
      "Batch Loss:  0.020072631537914276\n",
      "Batch Loss:  0.015548674389719963\n",
      "Batch Loss:  0.006096187047660351\n",
      "Batch Loss:  0.005981334485113621\n",
      "Batch Loss:  0.02781682461500168\n",
      "Batch Loss:  0.030967261642217636\n",
      "Batch Loss:  0.06243143230676651\n",
      "Batch Loss:  0.026565376669168472\n",
      "Batch Loss:  0.008781573735177517\n",
      "Batch Loss:  0.01346579473465681\n",
      "Batch Loss:  0.007865721359848976\n",
      "Batch Loss:  0.010551659390330315\n",
      "Batch Loss:  0.003913790453225374\n",
      "Batch Loss:  0.005173034965991974\n",
      "Batch Loss:  0.007270998787134886\n",
      "Batch Loss:  0.00914028100669384\n",
      "Batch Loss:  0.004371668212115765\n",
      "Batch Loss:  0.004012987948954105\n",
      "Batch Loss:  0.003837639931589365\n",
      "Batch Loss:  0.053535498678684235\n",
      "Batch Loss:  0.028221094980835915\n",
      "Batch Loss:  0.003463887609541416\n",
      "Batch Loss:  0.005676146596670151\n",
      "Batch Loss:  0.004791155457496643\n",
      "Batch Loss:  0.034256380051374435\n",
      "Batch Loss:  0.011695911176502705\n",
      "Batch Loss:  0.008736120536923409\n",
      "Batch Loss:  0.008812171407043934\n",
      "Batch Loss:  0.010154683142900467\n",
      "Batch Loss:  0.019050534814596176\n",
      "Batch Loss:  0.015968002378940582\n",
      "Batch Loss:  0.006630332209169865\n",
      "Batch Loss:  0.014419453218579292\n",
      "Batch Loss:  0.021873779594898224\n",
      "Batch Loss:  0.008636664599180222\n",
      "Batch Loss:  0.00875067338347435\n",
      "Batch Loss:  0.014923019334673882\n",
      "Batch Loss:  0.012786935083568096\n",
      "Batch Loss:  0.017692510038614273\n",
      "Batch Loss:  0.007644549943506718\n",
      "Batch Loss:  0.008316191844642162\n",
      "Batch Loss:  0.01851634681224823\n",
      "Batch Loss:  0.014290142804384232\n",
      "Batch Loss:  0.008995015174150467\n",
      "Batch Loss:  0.011375363916158676\n",
      "Batch Loss:  0.036178380250930786\n",
      "Batch Loss:  0.003807193599641323\n",
      "Batch Loss:  0.028557004407048225\n",
      "Batch Loss:  0.02323170006275177\n",
      "Batch Loss:  0.021934479475021362\n",
      "Batch Loss:  0.02088160067796707\n",
      "Batch Loss:  0.008697370067238808\n",
      "Batch Loss:  0.007347099483013153\n",
      "Batch Loss:  0.011176924221217632\n",
      "Batch Loss:  0.07101443409919739\n",
      "Batch Loss:  0.04680629074573517\n",
      "Batch Loss:  0.05557244271039963\n",
      "Batch Loss:  0.0832439661026001\n",
      "Batch Loss:  0.03771989792585373\n",
      "Batch Loss:  0.0555722713470459\n",
      "Batch Loss:  0.054718151688575745\n",
      "Batch Loss:  0.034301720559597015\n",
      "Batch Loss:  0.05992110073566437\n",
      "Batch Loss:  0.04532618820667267\n",
      "Batch Loss:  0.13908401131629944\n",
      "Batch Loss:  0.0673447698354721\n",
      "Batch Loss:  0.09309351444244385\n",
      "Batch Loss:  0.05030042305588722\n",
      "Batch Loss:  0.13127872347831726\n",
      "Batch Loss:  0.07574453949928284\n",
      "Batch Loss:  0.04730965942144394\n",
      "Batch Loss:  0.03292059153318405\n",
      "Batch Loss:  0.0073394314385950565\n",
      "Batch Loss:  0.0006106968503445387\n",
      "Batch Loss:  0.0011215039994567633\n",
      "Batch Loss:  0.0004042000509798527\n",
      "Batch Loss:  0.0007476924220100045\n",
      "Batch Loss:  0.0005342127988114953\n",
      "Batch Loss:  0.0009309660526923835\n",
      "Batch Loss:  0.0012665620306506753\n",
      "Batch Loss:  0.000961420068051666\n",
      "Batch Loss:  0.001533385831862688\n",
      "Batch Loss:  0.0013047801330685616\n",
      "Batch Loss:  0.00044252967927604914\n",
      "Batch Loss:  0.0750199630856514\n",
      "Batch Loss:  0.05255896970629692\n",
      "Batch Loss:  0.021621743217110634\n",
      "Batch Loss:  0.01708221808075905\n",
      "Batch Loss:  0.025818105787038803\n",
      "Batch Loss:  0.017646797001361847\n",
      "Batch Loss:  0.016883909702301025\n",
      "Batch Loss:  0.020027266815304756\n",
      "Batch Loss:  0.039955247193574905\n",
      "Batch Loss:  0.00970425270497799\n",
      "Batch Loss:  0.005859611555933952\n",
      "Batch Loss:  0.008293100632727146\n",
      "Batch Loss:  0.015541009604930878\n",
      "Batch Loss:  0.015975626185536385\n",
      "Batch Loss:  0.012527214363217354\n",
      "Batch Loss:  0.018661033362150192\n",
      "Batch Loss:  0.01271837204694748\n",
      "Batch Loss:  0.005561760161072016\n",
      "Batch Loss:  0.011375494301319122\n",
      "Batch Loss:  0.012389754876494408\n",
      "Batch Loss:  0.011306693777441978\n",
      "Batch Loss:  0.009277485311031342\n",
      "Batch Loss:  0.01988936960697174\n",
      "Batch Loss:  0.048835717141628265\n",
      "Batch Loss:  0.02876274660229683\n",
      "Batch Loss:  0.032600387930870056\n",
      "Batch Loss:  0.040802210569381714\n",
      "Batch Loss:  0.021324152126908302\n",
      "Batch Loss:  0.021629415452480316\n",
      "Batch Loss:  0.013351526111364365\n",
      "Batch Loss:  0.03329481929540634\n",
      "Batch Loss:  0.01131434552371502\n",
      "Batch Loss:  0.0400695726275444\n",
      "Batch Loss:  0.012558125890791416\n",
      "Batch Loss:  0.008720479905605316\n",
      "Batch Loss:  0.0036620567552745342\n",
      "Batch Loss:  0.005729604512453079\n",
      "Batch Loss:  0.007514497730880976\n",
      "Batch Loss:  0.012108096852898598\n",
      "Batch Loss:  0.004760772921144962\n",
      "Batch Loss:  0.0071563925594091415\n",
      "Batch Loss:  0.0037153929006308317\n",
      "Batch Loss:  0.002807529643177986\n",
      "Batch Loss:  0.003700179746374488\n",
      "Batch Loss:  0.004203620366752148\n",
      "Batch Loss:  0.006012069061398506\n",
      "Batch Loss:  0.007476458791643381\n",
      "Batch Loss:  0.005576740950345993\n",
      "Batch Loss:  0.003509512636810541\n",
      "Batch Loss:  0.005294786766171455\n",
      "Batch Loss:  0.0019302861765027046\n",
      "Batch Loss:  0.0002902854175772518\n",
      "Batch Loss:  0.0010758896823972464\n",
      "Batch Loss:  0.001105879433453083\n",
      "Batch Loss:  0.0002747878897935152\n",
      "Batch Loss:  0.0024259891360998154\n",
      "Batch Loss:  0.003196741919964552\n",
      "Batch Loss:  0.0001447228278266266\n",
      "Batch Loss:  0.0001526510459370911\n",
      "Batch Loss:  7.809347152942792e-06\n",
      "Batch Loss:  0.00012225122191011906\n",
      "Batch Loss:  0.017234861850738525\n",
      "Batch Loss:  0.020736748352646828\n",
      "Batch Loss:  0.025436513125896454\n",
      "Batch Loss:  0.0102080088108778\n",
      "Batch Loss:  0.02258315309882164\n",
      "Batch Loss:  0.0058975908905267715\n",
      "Batch Loss:  0.013457945547997952\n",
      "Batch Loss:  0.00899514276534319\n",
      "Batch Loss:  0.004997028969228268\n",
      "Batch Loss:  0.004325696732848883\n",
      "Batch Loss:  0.001350221922621131\n",
      "Batch Loss:  0.004631122574210167\n",
      "Batch Loss:  0.018493739888072014\n",
      "Batch Loss:  0.010757538489997387\n",
      "Batch Loss:  0.006034765392541885\n",
      "Batch Loss:  0.007743615657091141\n",
      "Batch Loss:  0.003715496975928545\n",
      "Batch Loss:  0.0005266588414087892\n",
      "Batch Loss:  0.0015947524225339293\n",
      "Batch Loss:  0.001228461740538478\n",
      "Batch Loss:  0.0002976775576826185\n",
      "Batch Loss:  0.002769622951745987\n",
      "Batch Loss:  0.00034321905695833266\n",
      "Batch Loss:  0.0031280824914574623\n",
      "Batch Loss:  0.00022139272186905146\n",
      "Batch Loss:  0.00017571874195709825\n",
      "Batch Loss:  -3.0397961381822824e-05\n",
      "Batch Loss:  7.809170710970648e-06\n",
      "Batch Loss:  2.2888387320563197e-05\n",
      "Batch Loss:  4.656612873077393e-10\n",
      "Batch Loss:  0.012389854528009892\n",
      "Batch Loss:  0.018943458795547485\n",
      "Batch Loss:  0.013244601897895336\n",
      "Batch Loss:  0.020225653424859047\n",
      "Batch Loss:  0.004180536605417728\n",
      "Batch Loss:  0.00798800028860569\n",
      "Batch Loss:  0.008888402953743935\n",
      "Batch Loss:  0.012771349400281906\n",
      "Batch Loss:  0.004753199405968189\n",
      "Batch Loss:  0.014083853922784328\n",
      "Batch Loss:  0.004752798471599817\n",
      "Batch Loss:  0.0043793730437755585\n",
      "Batch Loss:  0.011520251631736755\n",
      "Batch Loss:  0.012847870588302612\n",
      "Batch Loss:  0.0069655971601605415\n",
      "Batch Loss:  0.003517312929034233\n",
      "Batch Loss:  0.0023420248180627823\n",
      "Batch Loss:  0.009422357194125652\n",
      "Batch Loss:  0.0035933759063482285\n",
      "Batch Loss:  0.004249668680131435\n",
      "Batch Loss:  0.002227932680398226\n",
      "Batch Loss:  0.0022810730151832104\n",
      "Batch Loss:  0.0010376176796853542\n",
      "Batch Loss:  0.0015947433421388268\n",
      "Batch Loss:  0.0012509997468441725\n",
      "Batch Loss:  0.0004580290988087654\n",
      "Batch Loss:  6.86652201693505e-05\n",
      "Batch Loss:  0.00020611855143215507\n",
      "Batch Loss:  0.0002747272956185043\n",
      "Batch Loss:  0.00020623754244297743\n",
      "Batch Loss:  6.12745716352947e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss:  0.0002900467370636761\n",
      "Batch Loss:  -5.340497591532767e-05\n",
      "Batch Loss:  0.0008771205903030932\n",
      "Batch Loss:  0.0010224719299003482\n",
      "Batch Loss:  0.0003661729861050844\n",
      "Batch Loss:  0.0008928594179451466\n",
      "Batch Loss:  0.004837050102651119\n",
      "Batch Loss:  0.0050200289115309715\n",
      "Batch Loss:  0.0018307240679860115\n",
      "Batch Loss:  0.00851462036371231\n",
      "Batch Loss:  0.009948884136974812\n",
      "Batch Loss:  0.0062410831451416016\n",
      "Batch Loss:  0.0036696051247417927\n",
      "Batch Loss:  0.003151358338072896\n",
      "Batch Loss:  0.0011213712859898806\n",
      "Batch Loss:  0.0021514170803129673\n",
      "Batch Loss:  0.0016327988123521209\n",
      "Batch Loss:  0.0007247994653880596\n",
      "Batch Loss:  0.0004729918437078595\n",
      "Batch Loss:  0.0003509084926918149\n",
      "Batch Loss:  0.0001604589488124475\n",
      "Batch Loss:  6.984919309616089e-10\n",
      "Batch Loss:  0.0003810711787082255\n",
      "Batch Loss:  0.0004120701050851494\n",
      "Batch Loss:  0.0009994585998356342\n",
      "Batch Loss:  0.0002211999671999365\n",
      "Batch Loss:  0.0005265251966193318\n",
      "Batch Loss:  0.00016022109775803983\n",
      "Batch Loss:  0.00027466838946565986\n",
      "Batch Loss:  0.005806148052215576\n",
      "Batch Loss:  0.010101422667503357\n",
      "Batch Loss:  0.006057576276361942\n",
      "Batch Loss:  0.006805489771068096\n",
      "Batch Loss:  0.01103198155760765\n",
      "Batch Loss:  0.000503653078339994\n",
      "Batch Loss:  0.006622170098125935\n",
      "Batch Loss:  0.0059052882716059685\n",
      "Batch Loss:  0.012230101972818375\n",
      "Batch Loss:  0.004241766408085823\n",
      "Batch Loss:  0.00607291329652071\n",
      "Batch Loss:  0.005996663123369217\n",
      "Batch Loss:  0.0028537046164274216\n",
      "Batch Loss:  0.004798891022801399\n",
      "Batch Loss:  0.0020525134168565273\n",
      "Batch Loss:  0.0016019658651202917\n",
      "Batch Loss:  0.002044552005827427\n",
      "Batch Loss:  0.0005643267650157213\n",
      "Batch Loss:  0.0011519683757796884\n",
      "Batch Loss:  0.0003511467366479337\n",
      "Batch Loss:  1.525931293144822e-05\n",
      "Batch Loss:  0.00014514036593027413\n",
      "Batch Loss:  9.906451305141672e-05\n",
      "Batch Loss:  5.33467682544142e-05\n",
      "Batch Loss:  0.0001146221038652584\n",
      "Batch Loss:  8.398419595323503e-05\n",
      "Batch Loss:  0.00014496201765723526\n",
      "Batch Loss:  0.00022108035045675933\n",
      "Batch Loss:  0.00012177471944596618\n",
      "Batch Loss:  9.179295739158988e-05\n",
      "Batch Loss:  0.009223819710314274\n",
      "Batch Loss:  0.005813365802168846\n",
      "Batch Loss:  0.002723612356930971\n",
      "Batch Loss:  0.009445478208363056\n",
      "Batch Loss:  0.004386810585856438\n",
      "Batch Loss:  0.0001674581435509026\n",
      "Batch Loss:  0.002304415451362729\n",
      "Batch Loss:  0.0026014663744717836\n",
      "Batch Loss:  0.00679029431194067\n",
      "Batch Loss:  0.00518055958673358\n",
      "Batch Loss:  0.00305180624127388\n",
      "Batch Loss:  0.001518017495982349\n",
      "Batch Loss:  0.002449151361361146\n",
      "Batch Loss:  0.004669301211833954\n",
      "Batch Loss:  0.005462327040731907\n",
      "Batch Loss:  0.0027926054317504168\n",
      "Batch Loss:  0.0010989222209900618\n",
      "Batch Loss:  0.0014650545781478286\n",
      "Batch Loss:  0.00033577432623133063\n",
      "Batch Loss:  0.0007093837484717369\n",
      "Batch Loss:  0.0006027122726663947\n",
      "Batch Loss:  0.004737899173051119\n",
      "Batch Loss:  0.0020217825658619404\n",
      "Batch Loss:  0.002441239543259144\n",
      "Batch Loss:  0.0036466356832534075\n",
      "Batch Loss:  0.0024798500817269087\n",
      "Batch Loss:  0.004348743706941605\n",
      "Batch Loss:  0.0021441481076180935\n",
      "Batch Loss:  0.00084683921886608\n",
      "Batch Loss:  0.0035705622285604477\n",
      "Train Loss 27.175917967737405\n",
      "Epoch time 218.82515001296997\n",
      "Batch Loss:  0.0015185405500233173\n",
      "Batch Loss:  0.0003051961539313197\n",
      "Batch Loss:  0.00027454941300675273\n",
      "Batch Loss:  0.00053403404308483\n",
      "Batch Loss:  0.0006256010383367538\n",
      "Batch Loss:  0.0005492953932844102\n",
      "Batch Loss:  0.0002975582319777459\n",
      "Batch Loss:  3.796975579462014e-05\n",
      "Batch Loss:  0.00010675372323021293\n",
      "Batch Loss:  0.00013733195373788476\n",
      "Batch Loss:  0.00038148980820551515\n",
      "Batch Loss:  0.00024408992612734437\n",
      "Batch Loss:  0.0006637527840211987\n",
      "Batch Loss:  0.00033570750383660197\n",
      "Batch Loss:  0.0006407434120774269\n",
      "Batch Loss:  0.0010071475990116596\n",
      "Batch Loss:  0.0005339149502106011\n",
      "Batch Loss:  0.0003661738592199981\n",
      "Batch Loss:  0.0002592887030914426\n",
      "Batch Loss:  0.0004047360271215439\n",
      "Batch Loss:  0.0003810711787082255\n",
      "Batch Loss:  0.0024723303504288197\n",
      "Batch Loss:  0.000862393993884325\n",
      "Batch Loss:  0.0010146595304831862\n",
      "Batch Loss:  0.0014568241313099861\n",
      "Batch Loss:  0.0004425296210683882\n",
      "Batch Loss:  0.00041963873081840575\n",
      "Batch Loss:  0.0008317503379657865\n",
      "Batch Loss:  0.002052178606390953\n",
      "Batch Loss:  0.0016404776833951473\n",
      "Batch Loss:  0.0011136294342577457\n",
      "Batch Loss:  0.000457432703115046\n",
      "Batch Loss:  0.0007550839800387621\n",
      "Batch Loss:  0.0007782740285620093\n",
      "Batch Loss:  0.0009765626164153218\n",
      "Batch Loss:  0.0008617971907369792\n",
      "Batch Loss:  0.0007095967303030193\n",
      "Batch Loss:  0.0009462761809118092\n",
      "Batch Loss:  0.0018921801820397377\n",
      "Batch Loss:  0.0005419027875177562\n",
      "Batch Loss:  0.0007018472533673048\n",
      "Batch Loss:  0.0008316910825669765\n",
      "Batch Loss:  0.0007935959147289395\n",
      "Batch Loss:  0.0009080013260245323\n",
      "Batch Loss:  0.001045483280904591\n",
      "Batch Loss:  0.000740060699172318\n",
      "Batch Loss:  0.0016175804194062948\n",
      "Batch Loss:  0.0011673490516841412\n",
      "Batch Loss:  0.0011674086563289165\n",
      "Batch Loss:  0.0007094776956364512\n",
      "Batch Loss:  0.001403816626407206\n",
      "Batch Loss:  0.0008240001043304801\n",
      "Batch Loss:  0.0006713244365528226\n",
      "Batch Loss:  0.0007859050529077649\n",
      "Batch Loss:  0.0009537880541756749\n",
      "Batch Loss:  0.0014875917695462704\n",
      "Batch Loss:  0.0007931795553304255\n",
      "Batch Loss:  0.001167587237432599\n",
      "Batch Loss:  0.0011213805992156267\n",
      "Batch Loss:  0.0011290719266980886\n",
      "Batch Loss:  0.0018464417662471533\n",
      "Batch Loss:  -2.2887688828632236e-05\n",
      "Batch Loss:  -7.629074389114976e-06\n",
      "Batch Loss:  8.42822264530696e-05\n",
      "Batch Loss:  0.0001527699059806764\n",
      "Batch Loss:  5.3287221817299724e-05\n",
      "Batch Loss:  1.5558151062577963e-05\n",
      "Batch Loss:  -0.00012218678602948785\n",
      "Batch Loss:  0.000495762680657208\n",
      "Batch Loss:  -8.385037654079497e-05\n",
      "Batch Loss:  -0.0008312670979648829\n",
      "Batch Loss:  -0.0003277982759755105\n",
      "Batch Loss:  0.00030472580692730844\n",
      "Batch Loss:  0.00013727223267778754\n",
      "Batch Loss:  0.00042738852789625525\n",
      "Batch Loss:  0.0013276172103360295\n",
      "Batch Loss:  -1.5257333870977163e-05\n",
      "Batch Loss:  0.0009231520816683769\n",
      "Batch Loss:  0.0003131241537630558\n",
      "Batch Loss:  -0.00020607210171874613\n",
      "Batch Loss:  -0.00014507045852951705\n",
      "Batch Loss:  0.0002290689735673368\n",
      "Batch Loss:  7.691698556300253e-06\n",
      "Batch Loss:  0.00013721274444833398\n",
      "Batch Loss:  0.00027496591792441905\n",
      "Batch Loss:  0.0001295245165238157\n",
      "Batch Loss:  0.00028992921579629183\n",
      "Batch Loss:  0.00027454900555312634\n",
      "Batch Loss:  0.00022078212350606918\n",
      "Batch Loss:  0.0001832291018217802\n",
      "Batch Loss:  0.010726794600486755\n",
      "Batch Loss:  0.004348634742200375\n",
      "Batch Loss:  0.004676819778978825\n",
      "Batch Loss:  0.0057524582371115685\n",
      "Batch Loss:  0.0028530589770525694\n",
      "Batch Loss:  0.0014495397917926311\n",
      "Batch Loss:  0.003318729344755411\n",
      "Batch Loss:  0.003540030913427472\n",
      "Batch Loss:  0.0018694454338401556\n",
      "Batch Loss:  0.002097812481224537\n",
      "Batch Loss:  0.002723642159253359\n",
      "Batch Loss:  0.0015567224472761154\n",
      "Batch Loss:  0.0016554908361285925\n",
      "Batch Loss:  0.0041119493544101715\n",
      "Batch Loss:  0.006599436514079571\n",
      "Batch Loss:  0.0036161215975880623\n",
      "Batch Loss:  0.0013884021900594234\n",
      "Batch Loss:  0.0010677813552320004\n",
      "Batch Loss:  0.0007630136678926647\n",
      "Batch Loss:  0.00032795857987366617\n",
      "Batch Loss:  0.0005647941725328565\n",
      "Batch Loss:  0.00020564167061820626\n",
      "Batch Loss:  0.00012219238851685077\n",
      "Batch Loss:  6.86652201693505e-05\n",
      "Batch Loss:  8.380554936593398e-05\n",
      "Batch Loss:  -1.5258381608873606e-05\n",
      "Batch Loss:  -7.6290161814540625e-06\n",
      "Batch Loss:  7.570401066914201e-06\n",
      "Batch Loss:  5.35853068868164e-05\n",
      "Batch Loss:  0.0001374514540657401\n",
      "Batch Loss:  0.00010651546472217888\n",
      "Batch Loss:  1.5379519027192146e-05\n",
      "Batch Loss:  -6.121116894064471e-05\n",
      "Batch Loss:  0.00024432799546048045\n",
      "Batch Loss:  0.00014484193525277078\n",
      "Batch Loss:  0.00013733177911490202\n",
      "Batch Loss:  0.00029744207859039307\n",
      "Batch Loss:  0.0006868288619443774\n",
      "Batch Loss:  0.0010070318821817636\n",
      "Batch Loss:  0.001220593461766839\n",
      "Batch Loss:  0.0007249783375300467\n",
      "Batch Loss:  0.0005032739718444645\n",
      "Batch Loss:  0.000366536172805354\n",
      "Batch Loss:  0.0010911657009273767\n",
      "Batch Loss:  0.00022108029224909842\n",
      "Batch Loss:  0.0005035133217461407\n",
      "Batch Loss:  0.0005036346265114844\n",
      "Batch Loss:  0.00020588215556927025\n",
      "Batch Loss:  0.00032807866227813065\n",
      "Batch Loss:  0.00011468151933513582\n",
      "Batch Loss:  0.0006714442279189825\n",
      "Batch Loss:  0.0011138112749904394\n",
      "Batch Loss:  0.0005416044732555747\n",
      "Batch Loss:  0.00011462325346656144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss:  0.000336006487486884\n",
      "Batch Loss:  0.0007556811906397343\n",
      "Batch Loss:  0.0011294902069494128\n",
      "Batch Loss:  0.0002518393739592284\n",
      "Batch Loss:  0.0007781570311635733\n",
      "Batch Loss:  0.000786088639870286\n",
      "Batch Loss:  0.00038900028448551893\n",
      "Batch Loss:  0.00045015968498773873\n",
      "Batch Loss:  8.398390491493046e-05\n",
      "Batch Loss:  0.00038911812589503825\n",
      "Batch Loss:  0.0009310139575973153\n",
      "Batch Loss:  0.00045021966798231006\n",
      "Batch Loss:  0.0005571640213020146\n",
      "Batch Loss:  0.0003433972306083888\n",
      "Batch Loss:  0.0002747272956185043\n",
      "Batch Loss:  0.0002897487720474601\n",
      "Batch Loss:  0.0003585976373869926\n",
      "Batch Loss:  0.00025177831412293017\n",
      "Batch Loss:  0.00016791030066087842\n",
      "Batch Loss:  0.0003963909111917019\n",
      "Batch Loss:  0.00025171853485517204\n",
      "Batch Loss:  0.0003661686205305159\n",
      "Batch Loss:  0.0004578500520437956\n",
      "Batch Loss:  0.0004198183596599847\n",
      "Batch Loss:  0.0002365784312132746\n",
      "Batch Loss:  0.0003358277026563883\n",
      "Batch Loss:  0.00028211873723194003\n",
      "Batch Loss:  0.00024367126752622426\n",
      "Batch Loss:  0.00022865008213557303\n",
      "Batch Loss:  0.00022906770755071193\n",
      "Batch Loss:  0.000381607620511204\n",
      "Batch Loss:  0.000495822518132627\n",
      "Batch Loss:  0.00022900768090039492\n",
      "Batch Loss:  0.00021362886764109135\n",
      "Batch Loss:  0.00016796955605968833\n",
      "Batch Loss:  9.924304322339594e-05\n",
      "Batch Loss:  0.00022096146130934358\n",
      "Batch Loss:  0.00022131847799755633\n",
      "Batch Loss:  0.00042726914398372173\n",
      "Batch Loss:  0.000640682119410485\n",
      "Batch Loss:  0.0002743698132690042\n",
      "Batch Loss:  0.00016791006783023477\n",
      "Batch Loss:  7.629516767337918e-05\n",
      "Batch Loss:  8.392430027015507e-05\n",
      "Batch Loss:  0.0006331710028462112\n",
      "Batch Loss:  0.0002748470287770033\n",
      "Batch Loss:  0.00025922927306964993\n",
      "Batch Loss:  0.00022859082673676312\n",
      "Batch Loss:  0.0002900470863096416\n",
      "Batch Loss:  0.00046500287135131657\n",
      "Batch Loss:  0.00025922927306964993\n",
      "Batch Loss:  0.00042726914398372173\n",
      "Batch Loss:  0.00025946757523342967\n",
      "Batch Loss:  0.0003357077366672456\n",
      "Batch Loss:  0.00023657837300561368\n",
      "Batch Loss:  0.000358717079507187\n",
      "Batch Loss:  0.00022102025104686618\n",
      "Batch Loss:  0.0004346015048213303\n",
      "Batch Loss:  0.0004039017076138407\n",
      "Batch Loss:  0.00020594007219187915\n",
      "Batch Loss:  0.00026697819703258574\n",
      "Batch Loss:  6.866580224595964e-05\n",
      "Batch Loss:  0.0003205673419870436\n",
      "Batch Loss:  0.0007019664626568556\n",
      "Batch Loss:  0.00034333785879425704\n",
      "Batch Loss:  0.0004422914353199303\n",
      "Batch Loss:  0.001174622680991888\n",
      "Batch Loss:  0.0007785179186612368\n",
      "Batch Loss:  0.0002976776158902794\n",
      "Batch Loss:  0.000839145272038877\n",
      "Batch Loss:  0.00010687328176572919\n",
      "Batch Loss:  0.00046554062282666564\n",
      "Batch Loss:  0.00017518230015411973\n",
      "Batch Loss:  0.0004957035416737199\n",
      "Batch Loss:  0.0014727497473359108\n",
      "Batch Loss:  0.00036628980888053775\n",
      "Batch Loss:  7.593858026666567e-05\n",
      "Batch Loss:  0.0006101058679632843\n",
      "Batch Loss:  0.0006257850909605622\n",
      "Batch Loss:  0.00041236740071326494\n",
      "Batch Loss:  0.00074018380837515\n",
      "Batch Loss:  0.00019825209164991975\n",
      "Batch Loss:  0.0002823579416144639\n",
      "Batch Loss:  0.00027455080999061465\n",
      "Batch Loss:  0.0009078863076865673\n",
      "Batch Loss:  0.0006943948101252317\n",
      "Batch Loss:  6.878496060380712e-05\n",
      "Batch Loss:  0.00018334815104026347\n",
      "Batch Loss:  0.00010687264148145914\n",
      "Batch Loss:  0.00015277067723218352\n",
      "Batch Loss:  2.2888503735885024e-05\n",
      "Batch Loss:  6.878525164211169e-05\n",
      "Batch Loss:  0.0001680889690760523\n",
      "Batch Loss:  -3.814624506048858e-05\n",
      "Batch Loss:  0.00015253247693181038\n",
      "Batch Loss:  9.167317330138758e-05\n",
      "Batch Loss:  -7.688448022236116e-06\n",
      "Batch Loss:  3.051839303225279e-05\n",
      "Batch Loss:  5.352593871066347e-05\n",
      "Batch Loss:  8.386533590964973e-05\n",
      "Batch Loss:  0.0006713855545967817\n",
      "Batch Loss:  0.0003507301735226065\n",
      "Batch Loss:  0.0003741562832146883\n",
      "Batch Loss:  0.0005337991751730442\n",
      "Batch Loss:  0.0003812521754298359\n",
      "Batch Loss:  0.00042709216359071434\n",
      "Batch Loss:  0.00032801824272610247\n",
      "Batch Loss:  0.00023657878045924008\n",
      "Batch Loss:  0.0003891779633704573\n",
      "Batch Loss:  0.0006712086033076048\n",
      "Batch Loss:  0.0011750400299206376\n",
      "Batch Loss:  0.0009385289158672094\n",
      "Batch Loss:  0.0008772426517680287\n",
      "Batch Loss:  0.00048819257062859833\n",
      "Batch Loss:  0.00125893484801054\n",
      "Batch Loss:  0.00033541052835062146\n",
      "Batch Loss:  0.0006334708887152374\n",
      "Batch Loss:  0.0005261101177893579\n",
      "Batch Loss:  0.0005872118636034429\n",
      "Batch Loss:  0.001403697649948299\n",
      "Batch Loss:  0.0005802353844046593\n",
      "Batch Loss:  0.0007857907330617309\n",
      "Batch Loss:  0.0013350802473723888\n",
      "Batch Loss:  0.0003357076202519238\n",
      "Batch Loss:  0.00048062208225019276\n",
      "Batch Loss:  0.0005416044732555747\n",
      "Batch Loss:  0.0008775386959314346\n",
      "Batch Loss:  0.0032120738178491592\n",
      "Batch Loss:  5.364514800021425e-05\n",
      "Batch Loss:  -3.8027155824238434e-05\n",
      "Batch Loss:  0.00012946345668751746\n",
      "Batch Loss:  0.00019860817701555789\n",
      "Batch Loss:  0.00012219150085002184\n",
      "Batch Loss:  0.000648733286652714\n",
      "Batch Loss:  0.0003279593074694276\n",
      "Batch Loss:  0.0008242412004619837\n",
      "Batch Loss:  0.0003282589023001492\n",
      "Batch Loss:  0.00040462391916662455\n",
      "Batch Loss:  0.0006793212378397584\n",
      "Batch Loss:  0.0005801217630505562\n",
      "Batch Loss:  0.0005798179190605879\n",
      "Batch Loss:  0.0010070891585201025\n",
      "Batch Loss:  9.888687054626644e-05\n",
      "Batch Loss:  0.0004576713836286217\n",
      "Batch Loss:  0.00042732938891276717\n",
      "Batch Loss:  0.00018311088206246495\n",
      "Batch Loss:  0.00020611824584193528\n",
      "Batch Loss:  0.0004883707733824849\n",
      "Batch Loss:  0.0002821785456035286\n",
      "Batch Loss:  0.0007706433534622192\n",
      "Batch Loss:  0.0005108460318297148\n",
      "Batch Loss:  0.0003659915819298476\n",
      "Batch Loss:  0.0002898084348998964\n",
      "Batch Loss:  -3.8384663639590144e-05\n",
      "Batch Loss:  0.00020564167061820626\n",
      "Batch Loss:  7.641438423888758e-05\n",
      "Batch Loss:  3.0816241633147e-05\n",
      "Batch Loss:  0.0013276159297674894\n",
      "Batch Loss:  0.00022870989050716162\n",
      "Batch Loss:  0.00027472758665680885\n",
      "Batch Loss:  0.00023645887267775834\n",
      "Batch Loss:  0.0002443282282911241\n",
      "Batch Loss:  0.00122834462672472\n",
      "Batch Loss:  8.374583558179438e-05\n",
      "Batch Loss:  0.0007706432370468974\n",
      "Batch Loss:  0.0010224120924249291\n",
      "Batch Loss:  8.380700455745682e-05\n",
      "Batch Loss:  0.0007933579618111253\n",
      "Batch Loss:  0.0008012881735339761\n",
      "Batch Loss:  0.00034321885323151946\n",
      "Batch Loss:  0.001647872501052916\n",
      "Batch Loss:  0.0004349598311819136\n",
      "Batch Loss:  0.00025195773923769593\n",
      "Batch Loss:  9.942245378624648e-05\n",
      "Batch Loss:  0.00012219155905768275\n",
      "Batch Loss:  -0.00012969723320566118\n",
      "Batch Loss:  -7.568942237412557e-06\n",
      "Batch Loss:  0.0002818809007294476\n",
      "Batch Loss:  0.00011432389146648347\n",
      "Batch Loss:  0.00023646325280424207\n",
      "Batch Loss:  3.802831270149909e-05\n",
      "Batch Loss:  0.00017548006144352257\n",
      "Batch Loss:  9.930277155945078e-05\n",
      "Batch Loss:  7.570573870907538e-06\n",
      "Batch Loss:  0.0002518972032703459\n",
      "Batch Loss:  0.000595077988691628\n",
      "Batch Loss:  0.00032802060013636947\n",
      "Batch Loss:  1.5258905477821827e-05\n",
      "Train Loss 0.21101448260742472\n",
      "Epoch time 232.92003893852234\n",
      "Batch Loss:  0.00014478342200163752\n",
      "Batch Loss:  0.0007862040656618774\n",
      "Batch Loss:  0.00032062860555015504\n",
      "Batch Loss:  0.0005797614576295018\n",
      "Batch Loss:  0.0003208062844350934\n",
      "Batch Loss:  0.00011426502896938473\n",
      "Batch Loss:  0.0004043792432639748\n",
      "Batch Loss:  0.00016016160952858627\n",
      "Batch Loss:  0.00046542452764697373\n",
      "Batch Loss:  0.000419759307987988\n",
      "Batch Loss:  0.0003737388178706169\n",
      "Batch Loss:  0.000297438760753721\n",
      "Batch Loss:  0.0003584834630601108\n",
      "Batch Loss:  0.00046547988313250244\n",
      "Batch Loss:  8.364087261725217e-05\n",
      "Batch Loss:  6.84871047269553e-05\n",
      "Batch Loss:  0.00037362391594797373\n",
      "Batch Loss:  -0.00015258247731253505\n",
      "Batch Loss:  0.00020618234702851623\n",
      "Batch Loss:  0.00042709452100098133\n",
      "Batch Loss:  0.00025946757523342967\n",
      "Batch Loss:  0.00023634140961803496\n",
      "Batch Loss:  0.0005645557539537549\n",
      "Batch Loss:  0.0001751245727064088\n",
      "Batch Loss:  0.0005336776375770569\n",
      "Batch Loss:  0.00048056297237053514\n",
      "Batch Loss:  0.0005645566852763295\n",
      "Batch Loss:  0.00037391865043900907\n",
      "Batch Loss:  0.0004573732730932534\n",
      "Batch Loss:  0.0005492969648912549\n",
      "Batch Loss:  0.0018080425215885043\n",
      "Batch Loss:  0.0003660510410554707\n",
      "Batch Loss:  0.0005570448702201247\n",
      "Batch Loss:  0.0004043211229145527\n",
      "Batch Loss:  0.0006713841576129198\n",
      "Batch Loss:  0.000610159826464951\n",
      "Batch Loss:  0.0004348402435425669\n",
      "Batch Loss:  0.0009460977744311094\n",
      "Batch Loss:  0.00027496632537804544\n",
      "Batch Loss:  0.0007324304315261543\n",
      "Batch Loss:  0.0005493542994372547\n",
      "Batch Loss:  0.0005113883526064456\n",
      "Batch Loss:  0.0001907999103423208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss:  9.149539982900023e-05\n",
      "Batch Loss:  0.00019872919074259698\n",
      "Batch Loss:  0.000419640593463555\n",
      "Batch Loss:  0.0005951377679593861\n",
      "Batch Loss:  0.0007553852628916502\n",
      "Batch Loss:  0.00018317013746127486\n",
      "Batch Loss:  0.0001220728736370802\n",
      "Batch Loss:  0.0005110843339934945\n",
      "Batch Loss:  0.0005954356747679412\n",
      "Batch Loss:  0.0001220132689923048\n",
      "Batch Loss:  0.00016004366625566036\n",
      "Batch Loss:  0.0005873874761164188\n",
      "Batch Loss:  7.65938893891871e-05\n",
      "Batch Loss:  0.0002516614331398159\n",
      "Batch Loss:  0.00035848189145326614\n",
      "Batch Loss:  2.2651189283351414e-05\n",
      "Batch Loss:  4.5658201997866854e-05\n",
      "Batch Loss:  0.002716032788157463\n",
      "Batch Loss:  0.00025177831412293017\n",
      "Batch Loss:  9.92432760540396e-05\n",
      "Batch Loss:  4.583655754686333e-05\n",
      "Batch Loss:  7.653394277440384e-05\n",
      "Batch Loss:  7.629772881045938e-06\n",
      "Batch Loss:  0.00015998225717339665\n",
      "Batch Loss:  0.00012177471944596618\n",
      "Batch Loss:  0.00022149720462039113\n",
      "Batch Loss:  0.00019038241589441895\n",
      "Batch Loss:  0.00025940785417333245\n",
      "Batch Loss:  0.0001752416865201667\n",
      "Batch Loss:  0.0004122472309973091\n",
      "Batch Loss:  0.0008699058089405298\n",
      "Batch Loss:  0.00045779015636071563\n",
      "Batch Loss:  0.0003815480158664286\n",
      "Batch Loss:  0.0006410407368093729\n",
      "Batch Loss:  0.0008087979513220489\n",
      "Batch Loss:  0.0007401198381558061\n",
      "Batch Loss:  0.00035865759127773345\n",
      "Batch Loss:  0.0003814879455603659\n",
      "Batch Loss:  0.0006716221105307341\n",
      "Batch Loss:  0.00021315205958671868\n",
      "Batch Loss:  0.0003130566910840571\n",
      "Batch Loss:  0.0007782148895785213\n",
      "Batch Loss:  0.0003969866957049817\n",
      "Batch Loss:  0.000434780289651826\n",
      "Batch Loss:  0.00032032845774665475\n",
      "Batch Loss:  0.00038929752190597355\n",
      "Batch Loss:  0.0006103981868363917\n",
      "Batch Loss:  0.00046536061563529074\n",
      "Batch Loss:  0.0007172870682552457\n",
      "Batch Loss:  0.0004043783701490611\n",
      "Batch Loss:  0.0006257788045331836\n",
      "Batch Loss:  0.0006103388732299209\n",
      "Batch Loss:  0.00012988076196052134\n",
      "Batch Loss:  0.00021362880943343043\n",
      "Batch Loss:  0.0002061191335087642\n",
      "Batch Loss:  9.173295984510332e-05\n",
      "Batch Loss:  -9.918076102621853e-05\n",
      "Batch Loss:  3.039935472770594e-05\n",
      "Batch Loss:  7.599672971991822e-05\n",
      "Batch Loss:  -7.629289757460356e-05\n",
      "Batch Loss:  -1.5258206985890865e-05\n",
      "Batch Loss:  -4.577531944960356e-05\n",
      "Batch Loss:  7.611611363245174e-05\n",
      "Batch Loss:  1.1641532182693481e-10\n",
      "Batch Loss:  0.00012231135042384267\n",
      "Batch Loss:  1.195567165268585e-07\n",
      "Batch Loss:  -4.565640483633615e-05\n",
      "Batch Loss:  0.00010693359217839316\n",
      "Batch Loss:  0.00012994026474189013\n",
      "Batch Loss:  3.5780249163508415e-07\n",
      "Batch Loss:  -0.00010680995183065534\n",
      "Batch Loss:  3.057788489968516e-05\n",
      "Batch Loss:  7.617618393851444e-05\n",
      "Batch Loss:  -4.577601794153452e-05\n",
      "Batch Loss:  -6.854455568827689e-05\n",
      "Batch Loss:  6.109575042501092e-05\n",
      "Batch Loss:  -3.0516937840729952e-05\n",
      "Batch Loss:  0.004768418613821268\n",
      "Batch Loss:  0.00020600054995156825\n",
      "Batch Loss:  0.00014508041203953326\n",
      "Batch Loss:  0.0004043798544444144\n",
      "Batch Loss:  0.001220780424773693\n",
      "Batch Loss:  0.001403758767992258\n",
      "Batch Loss:  0.0007324325270019472\n",
      "Batch Loss:  0.0014952861238270998\n",
      "Batch Loss:  0.0006559437606483698\n",
      "Batch Loss:  0.00044247054029256105\n",
      "Batch Loss:  0.0005187161732465029\n",
      "Batch Loss:  0.0010985624976456165\n",
      "Batch Loss:  0.0003585389640647918\n",
      "Batch Loss:  0.0004579691158141941\n",
      "Batch Loss:  0.000587390037253499\n",
      "Batch Loss:  0.0009153402061201632\n",
      "Batch Loss:  0.00027454987866804004\n",
      "Batch Loss:  0.0001375105930492282\n",
      "Batch Loss:  0.00027454912196844816\n",
      "Batch Loss:  8.392464951612055e-05\n",
      "Batch Loss:  0.0004960615769959986\n",
      "Batch Loss:  0.0003663483657874167\n",
      "Batch Loss:  0.00038148852763697505\n",
      "Batch Loss:  0.000854406738653779\n",
      "Batch Loss:  0.0006712053436785936\n",
      "Batch Loss:  0.000388998887501657\n",
      "Batch Loss:  0.0006412849761545658\n",
      "Batch Loss:  3.814758383668959e-05\n",
      "Batch Loss:  0.00044235275709070265\n",
      "Batch Loss:  0.0005416664062067866\n",
      "Batch Loss:  0.0012970290845260024\n",
      "Batch Loss:  -4.5775785110890865e-05\n",
      "Batch Loss:  0.00017560008564032614\n",
      "Batch Loss:  -7.617351366207004e-05\n",
      "Batch Loss:  -0.00015234551392495632\n",
      "Batch Loss:  -1.5258498024195433e-05\n",
      "Batch Loss:  5.310852066031657e-05\n",
      "Batch Loss:  7.510447176173329e-06\n",
      "Batch Loss:  0.00041957947541959584\n",
      "Batch Loss:  0.0007708235643804073\n",
      "Batch Loss:  0.000640682119410485\n",
      "Batch Loss:  0.0005032185581512749\n",
      "Batch Loss:  0.0001679701526882127\n",
      "Batch Loss:  0.00021345028653740883\n",
      "Batch Loss:  0.0002898101811297238\n",
      "Batch Loss:  0.0005569878267124295\n",
      "Batch Loss:  0.0006713255424983799\n",
      "Batch Loss:  0.0005187144270166755\n",
      "Batch Loss:  0.0004047377733513713\n",
      "Batch Loss:  0.0003280780802015215\n",
      "Batch Loss:  0.0002443868143018335\n",
      "Batch Loss:  0.0003357076202519238\n",
      "Batch Loss:  0.0002517788961995393\n",
      "Batch Loss:  0.000411890767281875\n",
      "Batch Loss:  0.0005876364302821457\n",
      "Batch Loss:  0.0005187736242078245\n",
      "Batch Loss:  0.0004272097139619291\n",
      "Batch Loss:  7.635512156412005e-05\n",
      "Batch Loss:  0.0007020870689302683\n",
      "Batch Loss:  6.12380972597748e-08\n",
      "Batch Loss:  0.0007247991161420941\n",
      "Batch Loss:  -4.58943541161716e-05\n",
      "Batch Loss:  0.000297320366371423\n",
      "Batch Loss:  -5.867514119017869e-08\n",
      "Batch Loss:  0.0002214380365330726\n",
      "Batch Loss:  0.0003051882958970964\n",
      "Batch Loss:  0.00029737938893958926\n",
      "Batch Loss:  0.00028212094912305474\n",
      "Batch Loss:  0.0003665259573608637\n",
      "Batch Loss:  0.00045791020966134965\n",
      "Batch Loss:  0.0002593501703813672\n",
      "Batch Loss:  0.0005417237989604473\n",
      "Batch Loss:  0.0003813704242929816\n",
      "Batch Loss:  0.00026709787198342383\n",
      "Batch Loss:  0.00025166160776279867\n",
      "Batch Loss:  0.00019050229457207024\n",
      "Batch Loss:  5.3466097597265616e-05\n",
      "Batch Loss:  0.00016051936836447567\n",
      "Batch Loss:  0.00016016143490560353\n",
      "Batch Loss:  5.3585597925120965e-05\n",
      "Batch Loss:  0.000396750052459538\n",
      "Batch Loss:  0.000381489924620837\n",
      "Batch Loss:  0.0005567467305809259\n",
      "Batch Loss:  1.519976467534434e-05\n",
      "Batch Loss:  0.00012964443885721266\n",
      "Batch Loss:  0.00035102834226563573\n",
      "Batch Loss:  0.000496239576023072\n",
      "Batch Loss:  0.0005873874761164188\n",
      "Batch Loss:  0.0007094840984791517\n",
      "Batch Loss:  0.00023657878045924008\n",
      "Batch Loss:  0.00013739120913669467\n",
      "Batch Loss:  0.0001602810516487807\n",
      "Batch Loss:  7.629516767337918e-05\n",
      "Batch Loss:  0.00013739120913669467\n",
      "Batch Loss:  -5.352401058189571e-05\n",
      "Batch Loss:  3.07565787807107e-05\n",
      "Batch Loss:  0.00019842962501570582\n",
      "Batch Loss:  0.00013715302338823676\n",
      "Batch Loss:  0.0001676141400821507\n",
      "Batch Loss:  0.00019831035751849413\n",
      "Batch Loss:  0.0008011076133698225\n",
      "Batch Loss:  0.00026691879611462355\n",
      "Batch Loss:  0.00010693230433389544\n",
      "Batch Loss:  0.00046542196650989354\n",
      "Batch Loss:  6.097671212046407e-05\n",
      "Batch Loss:  0.00023657878045924008\n",
      "Batch Loss:  0.0004042606451548636\n",
      "Batch Loss:  0.00043513765558600426\n",
      "Batch Loss:  0.00027484737802296877\n",
      "Batch Loss:  0.00022883142810314894\n",
      "Batch Loss:  9.918402065522969e-05\n",
      "Batch Loss:  0.0003205079701729119\n",
      "Batch Loss:  0.00024432712234556675\n",
      "Batch Loss:  3.057788489968516e-05\n",
      "Batch Loss:  0.0002440887619741261\n",
      "Batch Loss:  0.000251541321631521\n",
      "Batch Loss:  0.0003203882952220738\n",
      "Batch Loss:  0.00028247677255421877\n",
      "Batch Loss:  0.0004881936765741557\n",
      "Batch Loss:  0.0002213191328337416\n",
      "Batch Loss:  0.0004196988884359598\n",
      "Batch Loss:  0.0001374509301967919\n",
      "Batch Loss:  0.00021333139738999307\n",
      "Batch Loss:  0.00042697275057435036\n",
      "Batch Loss:  6.908304203534499e-05\n",
      "Batch Loss:  -8.392237941734493e-05\n",
      "Batch Loss:  6.860648863948882e-05\n",
      "Batch Loss:  -7.748227289994247e-06\n",
      "Batch Loss:  0.0001906205725390464\n",
      "Batch Loss:  0.0002285911177750677\n",
      "Batch Loss:  0.00020611849322449416\n",
      "Batch Loss:  0.0002818804350681603\n",
      "Batch Loss:  0.00010675383964553475\n",
      "Batch Loss:  0.0002517780230846256\n",
      "Batch Loss:  0.00022137798077892512\n",
      "Batch Loss:  0.00022865025675855577\n",
      "Batch Loss:  0.00019860763859469444\n",
      "Batch Loss:  7.635442307218909e-05\n",
      "Batch Loss:  0.00027436966774985194\n",
      "Batch Loss:  0.00018317002104595304\n",
      "Batch Loss:  0.00021374819334596395\n",
      "Batch Loss:  0.00010699186532292515\n",
      "Batch Loss:  0.00041963908006437123\n",
      "Batch Loss:  0.0006334100035019219\n",
      "Batch Loss:  0.0008775363094173372\n",
      "Batch Loss:  0.001052876585163176\n",
      "Batch Loss:  0.00024414813378825784\n",
      "Batch Loss:  0.00038911812589503825\n",
      "Batch Loss:  0.0009459183784201741\n",
      "Batch Loss:  0.0003967492375522852\n",
      "Batch Loss:  0.0007631320040673018\n",
      "Batch Loss:  0.00044258945854380727\n",
      "Batch Loss:  0.000762654934078455\n",
      "Batch Loss:  0.00038148800376802683\n",
      "Batch Loss:  0.0005796378245577216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss:  0.00037344094016589224\n",
      "Batch Loss:  -3.814671072177589e-05\n",
      "Batch Loss:  0.00010699186532292515\n",
      "Batch Loss:  0.00032026873668655753\n",
      "Batch Loss:  0.00016785023035481572\n",
      "Batch Loss:  0.0001906205725390464\n",
      "Batch Loss:  0.00016791035886853933\n",
      "Batch Loss:  0.0003354690852575004\n",
      "Batch Loss:  3.814723459072411e-05\n",
      "Batch Loss:  -2.2887979866936803e-05\n",
      "Batch Loss:  0.0001528293505543843\n",
      "Batch Loss:  9.167404641630128e-05\n",
      "Batch Loss:  4.5837256038794294e-05\n",
      "Batch Loss:  7.570457455585711e-06\n",
      "Batch Loss:  0.0001754801778588444\n",
      "Batch Loss:  3.820719211944379e-05\n",
      "Batch Loss:  3.796923192567192e-05\n",
      "Batch Loss:  0.0003053673426620662\n",
      "Batch Loss:  0.0009614250739105046\n",
      "Batch Loss:  9.912558016367257e-05\n",
      "Batch Loss:  0.00038166940794326365\n",
      "Batch Loss:  0.0005569875938817859\n",
      "Batch Loss:  0.0001296424597967416\n",
      "Batch Loss:  0.0001221925049321726\n",
      "Batch Loss:  0.00030518817948177457\n",
      "Batch Loss:  0.0002592295641079545\n",
      "Batch Loss:  0.00017559927073307335\n",
      "Batch Loss:  0.00023634197714272887\n",
      "Batch Loss:  0.0003357677487656474\n",
      "Batch Loss:  0.0003051878302358091\n",
      "Batch Loss:  0.0003203290398232639\n",
      "Batch Loss:  0.00019801371672656387\n",
      "Batch Loss:  0.00022149743745103478\n",
      "Batch Loss:  6.061943349777721e-05\n",
      "Batch Loss:  0.0002058213867712766\n",
      "Batch Loss:  0.00016767316265031695\n",
      "Batch Loss:  0.0001906209217850119\n",
      "Batch Loss:  0.000267157272901386\n",
      "Batch Loss:  0.0007168705342337489\n",
      "Batch Loss:  8.398460340686142e-05\n",
      "Batch Loss:  0.00020599921117536724\n",
      "Batch Loss:  0.00010699233098421246\n",
      "Batch Loss:  -6.103463238105178e-05\n",
      "Batch Loss:  0.0001298808929277584\n",
      "Batch Loss:  0.00012219167547300458\n",
      "Batch Loss:  -4.565652125165798e-05\n",
      "Batch Loss:  9.125580982072279e-05\n",
      "Batch Loss:  2.9103830456733704e-10\n",
      "Batch Loss:  -6.866353214718401e-05\n",
      "Batch Loss:  -4.5656401198357344e-05\n",
      "Batch Loss:  9.119643800659105e-05\n",
      "Batch Loss:  -1.5139057722990401e-05\n",
      "Batch Loss:  6.830770144006237e-05\n",
      "Batch Loss:  -1.5258265193551779e-05\n",
      "Batch Loss:  0.00011468229058664292\n",
      "Batch Loss:  7.808822374499869e-06\n",
      "Batch Loss:  9.155418956652284e-05\n",
      "Batch Loss:  3.057788489968516e-05\n",
      "Batch Loss:  0.00016039973706938326\n",
      "Batch Loss:  0.00024408887838944793\n",
      "Batch Loss:  0.00024408934405073524\n",
      "Batch Loss:  0.0003587185638025403\n",
      "Batch Loss:  0.0002366976550547406\n",
      "Batch Loss:  9.155436418950558e-05\n",
      "Batch Loss:  0.00041958005749620497\n",
      "Batch Loss:  0.0002822991518769413\n",
      "Batch Loss:  0.0001373325358144939\n",
      "Batch Loss:  0.0001602205738890916\n",
      "Batch Loss:  0.0002977381809614599\n",
      "Batch Loss:  0.00019860794418491423\n",
      "Batch Loss:  0.0001372137339785695\n",
      "Batch Loss:  0.00022900775365997106\n",
      "Batch Loss:  0.00016802975733298808\n",
      "Batch Loss:  0.00011408557475078851\n",
      "Batch Loss:  -3.8145779399201274e-05\n",
      "Batch Loss:  0.00011456214269855991\n",
      "Batch Loss:  -9.143230272457004e-05\n",
      "Batch Loss:  9.942221367964521e-05\n",
      "Batch Loss:  6.83674807078205e-05\n",
      "Batch Loss:  9.930277155945078e-05\n",
      "Batch Loss:  5.346621401258744e-05\n",
      "Batch Loss:  -3.051705425605178e-05\n",
      "Batch Loss:  0.00013751041842624545\n",
      "Batch Loss:  -3.0278522899607196e-05\n",
      "Batch Loss:  -3.051687963306904e-05\n",
      "Batch Loss:  0.00012207234976813197\n",
      "Batch Loss:  0.0003204492968507111\n",
      "Batch Loss:  8.38647538330406e-05\n",
      "Batch Loss:  0.0003967484226450324\n",
      "Batch Loss:  0.00031269926694221795\n",
      "Batch Loss:  0.00019837036961689591\n",
      "Batch Loss:  0.00014502290287055075\n",
      "Batch Loss:  0.000412008841522038\n",
      "Batch Loss:  0.0008241210598498583\n",
      "Batch Loss:  0.00018299120711162686\n",
      "Batch Loss:  0.00035859787021763623\n",
      "Batch Loss:  0.00018322916002944112\n",
      "Batch Loss:  0.00041200907435268164\n",
      "Batch Loss:  0.00012988100934308022\n",
      "Batch Loss:  5.340666393749416e-05\n",
      "Batch Loss:  0.0001449025294277817\n",
      "Batch Loss:  7.641438423888758e-05\n",
      "Batch Loss:  3.0517810955643654e-05\n",
      "Batch Loss:  5.238689482212067e-10\n",
      "Batch Loss:  9.94221554719843e-05\n",
      "Batch Loss:  0.00011468140291981399\n",
      "Batch Loss:  8.398396312259138e-05\n",
      "Batch Loss:  -1.525861443951726e-05\n",
      "Batch Loss:  6.890393706271425e-05\n",
      "Batch Loss:  -9.918046998791397e-05\n",
      "Batch Loss:  -9.918046998791397e-05\n",
      "Batch Loss:  0.00012225123646203429\n",
      "Batch Loss:  8.398390491493046e-05\n",
      "Batch Loss:  8.398419595323503e-05\n",
      "Batch Loss:  -3.814653609879315e-05\n",
      "Batch Loss:  6.890451913932338e-05\n",
      "Batch Loss:  4.583655754686333e-05\n",
      "Train Loss 0.11830547371664579\n",
      "Epoch time 271.7505395412445\n",
      "Batch Loss:  9.894559480017051e-05\n",
      "Batch Loss:  0.00035108724841848016\n",
      "Batch Loss:  0.0001297621347475797\n",
      "Batch Loss:  0.00028992764418944716\n",
      "Batch Loss:  0.00035865846439264715\n",
      "Batch Loss:  0.00021350989118218422\n",
      "Batch Loss:  0.00038911812589503825\n",
      "Batch Loss:  0.00026709787198342383\n",
      "Batch Loss:  0.0002595887635834515\n",
      "Batch Loss:  6.848693010397255e-05\n",
      "Batch Loss:  0.00015253160381689668\n",
      "Batch Loss:  0.00010693276999518275\n",
      "Batch Loss:  0.0002977364929392934\n",
      "Batch Loss:  -7.68833160691429e-06\n",
      "Batch Loss:  0.00032026931876316667\n",
      "Batch Loss:  0.0004196389636490494\n",
      "Batch Loss:  0.0001982509857043624\n",
      "Batch Loss:  0.0002290675329277292\n",
      "Batch Loss:  0.0003430401557125151\n",
      "Batch Loss:  9.149510879069567e-05\n",
      "Batch Loss:  3.796888267970644e-05\n",
      "Batch Loss:  0.00021368893794715405\n",
      "Batch Loss:  0.0003509676898829639\n",
      "Batch Loss:  0.00047275429824367166\n",
      "Batch Loss:  0.00020593978115357459\n",
      "Batch Loss:  0.00022876996081322432\n",
      "Batch Loss:  0.00035853873123414814\n",
      "Batch Loss:  0.0001676716929068789\n",
      "Batch Loss:  0.00022894953144714236\n",
      "Batch Loss:  0.00010669475886970758\n",
      "Batch Loss:  0.001396126695908606\n",
      "Batch Loss:  0.00012976166908629239\n",
      "Batch Loss:  7.635442307218909e-05\n",
      "Batch Loss:  7.62965646572411e-06\n",
      "Batch Loss:  3.057835056097247e-05\n",
      "Batch Loss:  0.0002666207146830857\n",
      "Batch Loss:  0.0001373325358144939\n",
      "Batch Loss:  0.0006560635520145297\n",
      "Batch Loss:  0.0002820593654178083\n",
      "Batch Loss:  0.0002824178372975439\n",
      "Batch Loss:  0.00031257938826456666\n",
      "Batch Loss:  0.00018305081175640225\n",
      "Batch Loss:  6.860613939352334e-05\n",
      "Batch Loss:  8.398414502153173e-05\n",
      "Batch Loss:  9.92432760540396e-05\n",
      "Batch Loss:  0.0001604589488124475\n",
      "Batch Loss:  0.0001526509877294302\n",
      "Batch Loss:  0.00010693242802517489\n",
      "Batch Loss:  0.00020599956042133272\n",
      "Batch Loss:  0.00012976184370927513\n",
      "Batch Loss:  0.00016040010086726397\n",
      "Batch Loss:  0.00022847167565487325\n",
      "Batch Loss:  0.00012988083472009748\n",
      "Batch Loss:  0.0003816092503257096\n",
      "Batch Loss:  0.00036610953975468874\n",
      "Batch Loss:  0.0001676124957157299\n",
      "Batch Loss:  9.918471914716065e-05\n",
      "Batch Loss:  9.918402065522969e-05\n",
      "Batch Loss:  7.62360286898911e-05\n",
      "Batch Loss:  0.0003814896917901933\n",
      "Batch Loss:  0.007858248427510262\n",
      "Batch Loss:  0.003707817755639553\n",
      "Batch Loss:  0.004745445214211941\n",
      "Batch Loss:  0.0011138712288811803\n",
      "Batch Loss:  0.0025252336636185646\n",
      "Batch Loss:  0.003188987262547016\n",
      "Batch Loss:  0.0016094143502414227\n",
      "Batch Loss:  0.0024261679500341415\n",
      "Batch Loss:  0.0015412564389407635\n",
      "Batch Loss:  0.00027478975243866444\n",
      "Batch Loss:  0.0001604590070201084\n",
      "Batch Loss:  0.0001221925631398335\n",
      "Batch Loss:  -9.15509881451726e-05\n",
      "Batch Loss:  5.340614006854594e-05\n",
      "Batch Loss:  2.2888329112902284e-05\n",
      "Batch Loss:  -1.5020314094726928e-05\n",
      "Batch Loss:  0.00011462152178864926\n",
      "Batch Loss:  -3.0398079616134055e-05\n",
      "Batch Loss:  -4.5656637666979805e-05\n",
      "Batch Loss:  7.629423635080457e-06\n",
      "Batch Loss:  -9.918052819557488e-05\n",
      "Batch Loss:  1.5258847270160913e-05\n",
      "Batch Loss:  8.398402133025229e-05\n",
      "Batch Loss:  -3.039807779714465e-05\n",
      "Batch Loss:  2.2888503735885024e-05\n",
      "Batch Loss:  6.109545938670635e-05\n",
      "Batch Loss:  9.161344496533275e-05\n",
      "Batch Loss:  7.748863936285488e-06\n",
      "Batch Loss:  -5.340515053831041e-05\n",
      "Batch Loss:  0.00888054072856903\n",
      "Batch Loss:  0.04207589477300644\n",
      "Batch Loss:  0.0013504524249583483\n",
      "Batch Loss:  0.00026715724379755557\n",
      "Batch Loss:  0.00030524726025760174\n",
      "Batch Loss:  0.00018305255798622966\n",
      "Batch Loss:  0.00034321981365792453\n",
      "Batch Loss:  0.000282357883406803\n",
      "Batch Loss:  0.00018293158791493624\n",
      "Batch Loss:  0.0008087450405582786\n",
      "Batch Loss:  0.000175599503563717\n",
      "Batch Loss:  0.002036972437053919\n",
      "Batch Loss:  0.00031269891769625247\n",
      "Batch Loss:  0.00017524186114314944\n",
      "Batch Loss:  0.0004577899817377329\n",
      "Batch Loss:  0.00012976166908629239\n",
      "Batch Loss:  0.0002518378314562142\n",
      "Batch Loss:  -3.051687963306904e-05\n",
      "Batch Loss:  -9.155110456049442e-05\n",
      "Batch Loss:  2.3007654817774892e-05\n",
      "Batch Loss:  6.0797952755820006e-05\n",
      "Batch Loss:  -3.051687963306904e-05\n",
      "Batch Loss:  -7.629132596775889e-06\n",
      "Batch Loss:  3.814723459072411e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss:  6.109580863267183e-05\n",
      "Batch Loss:  -7.629190804436803e-06\n",
      "Batch Loss:  -3.0398079616134055e-05\n",
      "Batch Loss:  0.00010681344429031014\n",
      "Batch Loss:  -7.449732947861776e-06\n",
      "Batch Loss:  5.340614006854594e-05\n",
      "Batch Loss:  3.0517810955643654e-05\n",
      "Batch Loss:  0.0026549603790044785\n",
      "Batch Loss:  0.00018316967179998755\n",
      "Batch Loss:  6.115530413808301e-05\n",
      "Batch Loss:  9.930277155945078e-05\n",
      "Batch Loss:  0.00012213218724355102\n",
      "Batch Loss:  0.00010699233098421246\n",
      "Batch Loss:  7.570399247924797e-06\n",
      "Batch Loss:  3.0458495530183427e-05\n",
      "Batch Loss:  0.0002897489466704428\n",
      "Batch Loss:  3.808774636127055e-05\n",
      "Batch Loss:  6.84871047269553e-05\n",
      "Batch Loss:  0.0002594089019112289\n",
      "Batch Loss:  0.0004421123885549605\n",
      "Batch Loss:  0.00022894830908626318\n",
      "Batch Loss:  6.854664388811216e-05\n",
      "Batch Loss:  8.398390491493046e-05\n",
      "Batch Loss:  2.2829073714092374e-05\n",
      "Batch Loss:  0.00017524157010484487\n",
      "Batch Loss:  0.00022882904158905149\n",
      "Batch Loss:  0.0004196388472337276\n",
      "Batch Loss:  0.00027448905166238546\n",
      "Batch Loss:  5.328698898665607e-05\n",
      "Batch Loss:  0.00031281853443942964\n",
      "Batch Loss:  0.00028992939041927457\n",
      "Batch Loss:  0.0006026499904692173\n",
      "Batch Loss:  9.149848483502865e-05\n",
      "Batch Loss:  0.00012958337902091444\n",
      "Batch Loss:  0.00011444339179433882\n",
      "Batch Loss:  0.0001680886634858325\n",
      "Batch Loss:  0.00016045912343543023\n",
      "Batch Loss:  7.570166417281143e-06\n",
      "Batch Loss:  0.00013739120913669467\n",
      "Batch Loss:  2.2888503735885024e-05\n",
      "Batch Loss:  7.635465590283275e-05\n",
      "Batch Loss:  -7.629132596775889e-06\n",
      "Batch Loss:  3.051804378628731e-05\n",
      "Batch Loss:  0.00013751066580880433\n",
      "Batch Loss:  7.629423635080457e-06\n",
      "Batch Loss:  2.2411546524381265e-05\n",
      "Batch Loss:  6.07974870945327e-05\n",
      "Batch Loss:  -6.091519389883615e-05\n",
      "Batch Loss:  1.5259196516126394e-05\n",
      "Batch Loss:  -6.091519389883615e-05\n",
      "Batch Loss:  7.868015018175356e-06\n",
      "Batch Loss:  1.51403910422232e-05\n",
      "Batch Loss:  -3.0517345294356346e-05\n",
      "Batch Loss:  -6.09149610681925e-05\n",
      "Batch Loss:  -1.5258672647178173e-05\n",
      "Batch Loss:  7.748748430458363e-06\n",
      "Batch Loss:  0.00010663473221939057\n",
      "Batch Loss:  -7.6290161814540625e-06\n",
      "Batch Loss:  8.416330820182338e-05\n",
      "Batch Loss:  -7.6290161814540625e-06\n",
      "Batch Loss:  2.3283064365386963e-10\n",
      "Batch Loss:  -3.0517345294356346e-05\n",
      "Batch Loss:  4.577671643346548e-05\n",
      "Batch Loss:  1.525896368548274e-05\n",
      "Batch Loss:  3.820742495008744e-05\n",
      "Batch Loss:  1.195003278553486e-07\n",
      "Batch Loss:  -8.368385169887915e-05\n",
      "Batch Loss:  -3.814653609879315e-05\n",
      "Batch Loss:  -2.2887979866936803e-05\n",
      "Batch Loss:  0.00012994026474189013\n",
      "Batch Loss:  -3.0517112463712692e-05\n",
      "Batch Loss:  7.641467527719215e-05\n",
      "Batch Loss:  0.00020623748423531651\n",
      "Batch Loss:  0.00015265069669112563\n",
      "Batch Loss:  0.00010681344429031014\n",
      "Batch Loss:  0.0001525908592157066\n",
      "Batch Loss:  0.0001298217539442703\n",
      "Batch Loss:  9.167317330138758e-05\n",
      "Batch Loss:  6.866539479233325e-05\n",
      "Batch Loss:  0.00019860794418491423\n",
      "Batch Loss:  0.000266918505076319\n",
      "Batch Loss:  0.00019842927576974034\n",
      "Batch Loss:  6.103637861087918e-05\n",
      "Batch Loss:  0.00025189787265844643\n",
      "Batch Loss:  0.000183289113920182\n",
      "Batch Loss:  9.149423567578197e-05\n",
      "Batch Loss:  0.00016791006783023477\n",
      "Batch Loss:  1.531944508315064e-05\n",
      "Batch Loss:  0.0002520765410736203\n",
      "Batch Loss:  0.00011456202628323808\n",
      "Batch Loss:  0.00019085904932580888\n",
      "Batch Loss:  5.364484968595207e-05\n",
      "Batch Loss:  0.0002899278770200908\n",
      "Batch Loss:  -3.8146128645166755e-05\n",
      "Batch Loss:  0.0002137483679689467\n",
      "Batch Loss:  0.00014508093590848148\n",
      "Batch Loss:  0.000358717079507187\n",
      "Batch Loss:  0.0001909186685224995\n",
      "Batch Loss:  0.0002821783418767154\n",
      "Batch Loss:  0.00025964630185626447\n",
      "Batch Loss:  7.629423635080457e-06\n",
      "Batch Loss:  0.00015265069669112563\n",
      "Batch Loss:  3.814723459072411e-05\n",
      "Batch Loss:  9.167358075501397e-05\n",
      "Batch Loss:  0.00010663485591067001\n",
      "Batch Loss:  0.00013733148807659745\n",
      "Batch Loss:  6.103568011894822e-05\n",
      "Batch Loss:  0.0002749064296949655\n",
      "Batch Loss:  -5.316667375154793e-05\n",
      "Batch Loss:  0.0001680886634858325\n",
      "Batch Loss:  5.346615580492653e-05\n",
      "Batch Loss:  5.346598118194379e-05\n",
      "Batch Loss:  9.924298501573503e-05\n",
      "Batch Loss:  0.00042697126627899706\n",
      "Batch Loss:  0.00012970223906449974\n",
      "Batch Loss:  0.0001603406126378104\n",
      "Batch Loss:  0.0006106368382461369\n",
      "Batch Loss:  7.635459769517183e-05\n",
      "Batch Loss:  1.5258847270160913e-05\n",
      "Batch Loss:  0.00012225123646203429\n",
      "Batch Loss:  0.00017571862554177642\n",
      "Batch Loss:  0.0003053664695471525\n",
      "Batch Loss:  0.0003665259573608637\n",
      "Batch Loss:  9.924298501573503e-05\n",
      "Batch Loss:  0.00022912691929377615\n",
      "Batch Loss:  0.00016033989959396422\n",
      "Batch Loss:  0.00015276978956535459\n",
      "Batch Loss:  0.0002825366682372987\n",
      "Batch Loss:  0.00016033989959396422\n",
      "Batch Loss:  9.155407315120101e-05\n",
      "Batch Loss:  0.00019860794418491423\n",
      "Batch Loss:  3.051769454032183e-05\n",
      "Batch Loss:  -0.00012194918235763907\n",
      "Batch Loss:  9.930265514412895e-05\n",
      "Batch Loss:  5.358519047149457e-05\n",
      "Batch Loss:  9.167311509372666e-05\n",
      "Batch Loss:  -7.509808710892685e-06\n",
      "Batch Loss:  -2.2768192138755694e-05\n",
      "Batch Loss:  7.629423635080457e-06\n",
      "Batch Loss:  -5.3286057664081454e-05\n",
      "Batch Loss:  -6.103469058871269e-05\n",
      "Batch Loss:  3.069726881221868e-05\n",
      "Batch Loss:  0.0001070517537300475\n",
      "Batch Loss:  5.3466097597265616e-05\n",
      "Batch Loss:  3.051775274798274e-05\n",
      "Batch Loss:  0.00013756997941527516\n",
      "Batch Loss:  -6.854449748061597e-05\n",
      "Batch Loss:  -3.0517345294356346e-05\n",
      "Batch Loss:  7.593706686748192e-05\n",
      "Batch Loss:  8.362621156265959e-05\n",
      "Batch Loss:  3.051775274798274e-05\n",
      "Batch Loss:  -8.380317012779415e-05\n",
      "Batch Loss:  0.00011462152178864926\n",
      "Batch Loss:  -5.328617407940328e-05\n",
      "Batch Loss:  9.167357347905636e-05\n",
      "Batch Loss:  6.109545938670635e-05\n",
      "Batch Loss:  5.238689482212067e-10\n",
      "Batch Loss:  -7.62930721975863e-06\n",
      "Batch Loss:  7.629423635080457e-06\n",
      "Batch Loss:  0.0001145029382314533\n",
      "Batch Loss:  0.00011438308865763247\n",
      "Batch Loss:  0.00016034059808589518\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from models import Backbone as Model\n",
    "\n",
    "model = Model().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "loss = ConstrastiveLoss(device=device)\n",
    "\n",
    "run_name = 'Ten videos per epoch rotating'\n",
    "with mlflow.start_run(run_name = run_name) as run:\n",
    "    for key, value in vars(args).items():\n",
    "        mlflow.log_param(key, value)\n",
    "\n",
    "    mlflow.log_param('Parameters', count_parameters(model))\n",
    "\n",
    "    for epoch, items in enumerate(train(model, loss, optimizer)):\n",
    "        for key, value in items:\n",
    "            print(key, value)\n",
    "            mlflow.log_metric(key, value, epoch)\n",
    "\n",
    "    torch.save({\n",
    "        'model':model.state_dict(),\n",
    "        'optimizer':optimizer.state_dict(),\n",
    "        }, 'run_stats.pyt')\n",
    "    mlflow.log_artifact('run_stats.pyt')\n",
    "\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "#     # save an architecture diagram\n",
    "#     HL.transforms.Fold(\"Conv > BatchNorm > Relu\", \"ConvBnRelu\"),\n",
    "#     HL.build_graph(model, torch.zeros([args.batch_size, 3, 288, 512]).to(device)).save('architecture', format='png')\n",
    "#     mlflow.log_artifact('architecture.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
